{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "# import warnings\n",
    "import warnings\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e677dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv (comma separated value) into data\n",
    "data = pd.read_csv('../input/column_2C_weka.csv')\n",
    "print(plt.style.available) # look at available plot styles\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28550dc1",
   "metadata": {},
   "source": [
    "\n",
    "# A. SUPERVISED LEARNING\n",
    "Supervised learning: It uses data that has labels. Example, there are orthopedic patients data that have labels normal and abnormal.\n",
    "There are features(predictor variable) and target variable. Features are like pelvic radius or sacral slope(If you have no idea what these are like me, you can look images in google like what I did :) )Target variables are labels normal and abnormal\n",
    "Aim is that as given features(input) predict whether target variable(output) is normal or abnormal\n",
    "Classification: target variable consists of categories like normal or abnormal\n",
    "Regression: target variable is continious like stock market\n",
    "If these explanations are not enough for you, just google them. However, be careful about terminology: features = predictor variable = independent variable = columns = inputs. target variable = responce variable = class = dependent variable = output = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce4b6f",
   "metadata": {},
   "source": [
    "\n",
    "# EXPLORATORY DATA ANALYSIS (EDA)\n",
    "In order to make something in data, as you know you need to explore data. Detailed exploratory data analysis is in my Data Science Tutorial for Beginners\n",
    "\n",
    "I always start with head() to see features that are pelvic_incidence, pelvic_tilt numeric, lumbar_lordosis_angle, sacral_slope, pelvic_radius and degree_spondylolisthesis and target variable that is class\n",
    "\n",
    "head(): default value of it shows first 5 rows(samples). If you want to see for example 100 rows just write head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d877230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see features and target variable\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well know question is is there any NaN value and length of this data so lets look at info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a53cc",
   "metadata": {},
   "source": [
    "pd.plotting.scatter_matrix:\n",
    "\n",
    "green: normal and red: abnormal\n",
    "\n",
    "c: color\n",
    "\n",
    "figsize: figure size\n",
    "\n",
    "diagonal: histohram of each features\n",
    "\n",
    "alpha: opacity\n",
    "\n",
    "s: size of marker\n",
    "\n",
    "marker: marker type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\n",
    "pd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n",
    "                                       c=color_list,\n",
    "                                       figsize= [15,15],\n",
    "                                       diagonal='hist',\n",
    "                                       alpha=0.5,\n",
    "                                       s = 200,\n",
    "                                       marker = '*',\n",
    "                                       edgecolor= \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4b71c",
   "metadata": {},
   "source": [
    "Okay, as you understand in scatter matrix there are relations between each feature but how many normal(green) and abnormal(red) classes are there.\n",
    "\n",
    "Searborn library has countplot() that counts number of classes\n",
    "\n",
    "Also you can print it with value_counts() method\n",
    "\n",
    "This data looks like balanced. Actually there is no definiton or numeric value of balanced data but this data is balanced enough for us.\n",
    "Now lets learn first classification method KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9013465",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"class\", data=data)\n",
    "data.loc[:,'class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92f5b6",
   "metadata": {},
   "source": [
    "\n",
    "# PRE-PROCESSING DATA\n",
    "In real life data can include objects or categorical data in order to use them in sklearn we need to encode them into numerical data\n",
    "\n",
    "In data, class is abnormal and normal. Lets convert them into numeric value (actually I did it in logistic regression part with different method)\n",
    "\n",
    "2 different feature is created with the name class_Abnormal and class_Normal\n",
    "\n",
    "However we need to drop one of the column because they are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('../input/column_2C_weka.csv')\n",
    "# get_dummies\n",
    "df = pd.get_dummies(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e15534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one of the feature\n",
    "df.drop(\"class_Normal\",axis = 1, inplace = True) \n",
    "df.head(10)\n",
    "# instead of two steps we can make it with one step pd.get_dummies(data,drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04289ac9",
   "metadata": {},
   "source": [
    "# Other preprocessing step is centering, scaling or normalizing\n",
    "\n",
    "If you listen my advice and watch KNN in youtube, you have noticed that KNN uses form of distance for classificaiton like some oher methods. Therefore, we need to scale data. For this reason, we use\n",
    "\n",
    " standardization: ( x - x.mean) / x.variance or x - x.min / x.range\n",
    "pipeline: The purpose of the pipeline is to assemble several steps like svm(classifier) and standardization(pre-processing)\n",
    "\n",
    "How we create parameters name: for example SVM_ _C : stepName__parameterName\n",
    "\n",
    "Then grid search to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM, pre-process and pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "steps = [('scalar', StandardScaler()),\n",
    "         ('SVM', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'SVM__C':[1, 10, 100],\n",
    "              'SVM__gamma':[0.1, 0.01]}\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 1)\n",
    "cv = GridSearchCV(pipeline,param_grid=parameters,cv=3)\n",
    "cv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = cv.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: {}\".format(cv.score(x_test, y_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23c253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe3eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce33bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e0379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d64c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c921fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
